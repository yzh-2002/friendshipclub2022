{"version":3,"sources":["index.js","grammar.js","number-literals.js","string-literals.js","tokenizer.js"],"names":[],"mappings":";;;;;;;AAAA;AACA;AACA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA;ACFA,ADGA,AENA;ADIA,ADGA,AENA;ADIA,ADGA,AENA;ADIA,ADGA,AENA,ACHA;AFOA,ADGA,AENA,ACHA;AFOA,ADGA,AENA,ACHA;AFOA,ADGA,AENA,ACHA,ACHA;AHUA,ADGA,AENA,ACHA,ACHA;AHUA,ADGA,AENA,ACHA,ACHA;AHUA,ADGA,AENA,ACHA,ACHA;AHUA,ADGA,AENA,ACHA,ACHA;AHUA,ADGA,AENA,ACHA,ACHA;AHUA,ADGA,AENA,ACHA,ACHA;AHUA,ADGA,AENA,ACHA,ACHA;AHUA,ADGA,AENA,ACHA,ACHA;AHUA,ADGA,AENA,ACHA,ACHA;AHUA,ADGA,AENA,ACHA,ACHA;AHUA,ADGA,AENA,ACHA,ACHA;AHUA,ADGA,AENA,ACHA,ACHA;AHUA,ADGA,AENA,ACHA,ACHA;AHUA,ADGA,AENA,ACHA,ACHA;AHUA,ADGA,AENA,ACHA,ACHA;AHUA,ADGA,AENA,ACHA,ACHA;AHUA,ADGA,AENA,ACHA,ACHA;AHUA,ADGA,AENA,ACHA,ACHA;AHUA,ADGA,AENA,ACHA,ACHA;AHUA,ADGA,AENA,ACHA,ACHA;AHUA,ADGA,AENA,ACHA,ACHA;AHUA,ADGA,AENA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,ACHA,ACHA;AHUA,ACHA,AENA;AHUA,ACHA,AENA;AHUA,ACHA,AENA;AHUA,ACHA,AENA;AHUA,ACHA,AENA;AHUA,ACHA,AENA;AHUA,ACHA,AENA;AHUA,ACHA,AENA;AHUA,ACHA,AENA;AHUA,ACHA,AENA;AHUA,ACHA,AENA;AHUA,ACHA,AENA;AHUA,ACHA,AENA;AHUA,ACHA,AENA;AHUA,ACHA,AENA;AHUA,ACHA,AENA;AHUA,ACHA,AENA;AHUA,ACHA,AENA;AHUA,ACHA,AENA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA,AGTA;AHUA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","file":"index.js","sourcesContent":["\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nvar _exportNames = {\n  parse: true\n};\nexports.parse = parse;\n\nvar parser = _interopRequireWildcard(require(\"./grammar\"));\n\nvar _tokenizer = require(\"./tokenizer\");\n\nvar _numberLiterals = require(\"./number-literals\");\n\nObject.keys(_numberLiterals).forEach(function (key) {\n  if (key === \"default\" || key === \"__esModule\") return;\n  if (Object.prototype.hasOwnProperty.call(_exportNames, key)) return;\n  Object.defineProperty(exports, key, {\n    enumerable: true,\n    get: function get() {\n      return _numberLiterals[key];\n    }\n  });\n});\n\nfunction _interopRequireWildcard(obj) { if (obj && obj.__esModule) { return obj; } else { var newObj = {}; if (obj != null) { for (var key in obj) { if (Object.prototype.hasOwnProperty.call(obj, key)) { var desc = Object.defineProperty && Object.getOwnPropertyDescriptor ? Object.getOwnPropertyDescriptor(obj, key) : {}; if (desc.get || desc.set) { Object.defineProperty(newObj, key, desc); } else { newObj[key] = obj[key]; } } } } newObj.default = obj; return newObj; } }\n\nfunction parse(source) {\n  var tokens = (0, _tokenizer.tokenize)(source); // We pass the source here to show code frames\n\n  var ast = parser.parse(tokens, source);\n  return ast;\n}","\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.parse = parse;\n\nvar _helperCodeFrame = require(\"@webassemblyjs/helper-code-frame\");\n\nvar t = _interopRequireWildcard(require(\"@webassemblyjs/ast\"));\n\nvar _numberLiterals = require(\"./number-literals\");\n\nvar _stringLiterals = require(\"./string-literals\");\n\nvar _tokenizer = require(\"./tokenizer\");\n\nfunction _interopRequireWildcard(obj) { if (obj && obj.__esModule) { return obj; } else { var newObj = {}; if (obj != null) { for (var key in obj) { if (Object.prototype.hasOwnProperty.call(obj, key)) { var desc = Object.defineProperty && Object.getOwnPropertyDescriptor ? Object.getOwnPropertyDescriptor(obj, key) : {}; if (desc.get || desc.set) { Object.defineProperty(newObj, key, desc); } else { newObj[key] = obj[key]; } } } } newObj.default = obj; return newObj; } }\n\nfunction _typeof(obj) { if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { _typeof = function _typeof(obj) { return typeof obj; }; } else { _typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return _typeof(obj); }\n\nfunction _toConsumableArray(arr) { if (Array.isArray(arr)) { for (var i = 0, arr2 = new Array(arr.length); i < arr.length; i++) { arr2[i] = arr[i]; } return arr2; } else { return Array.from(arr); } }\n\nfunction hasPlugin(name) {\n  if (name !== \"wast\") throw new Error(\"unknow plugin\");\n  return true;\n}\n\nfunction isKeyword(token, id) {\n  return token.type === _tokenizer.tokens.keyword && token.value === id;\n}\n\nfunction tokenToString(token) {\n  if (token.type === \"keyword\") {\n    return \"keyword (\".concat(token.value, \")\");\n  }\n\n  return token.type;\n}\n\nfunction identifierFromToken(token) {\n  var _token$loc = token.loc,\n      end = _token$loc.end,\n      start = _token$loc.start;\n  return t.withLoc(t.identifier(token.value), end, start);\n}\n\nfunction parse(tokensList, source) {\n  var current = 0;\n  var getUniqueName = t.getUniqueNameGenerator();\n  var state = {\n    registredExportedElements: []\n  }; // But this time we're going to use recursion instead of a `while` loop. So we\n  // define a `walk` function.\n\n  function walk() {\n    var token = tokensList[current];\n\n    function eatToken() {\n      token = tokensList[++current];\n    }\n\n    function getEndLoc() {\n      var currentToken = token;\n\n      if (typeof currentToken === \"undefined\") {\n        var lastToken = tokensList[tokensList.length - 1];\n        currentToken = lastToken;\n      }\n\n      return currentToken.loc.end;\n    }\n\n    function getStartLoc() {\n      return token.loc.start;\n    }\n\n    function eatTokenOfType(type) {\n      if (token.type !== type) {\n        throw new Error(\"\\n\" + (0, _helperCodeFrame.codeFrameFromSource)(source, token.loc) + \"Assertion error: expected token of type \" + type + \", given \" + tokenToString(token));\n      }\n\n      eatToken();\n    }\n\n    function parseExportIndex(token) {\n      if (token.type === _tokenizer.tokens.identifier) {\n        var index = identifierFromToken(token);\n        eatToken();\n        return index;\n      } else if (token.type === _tokenizer.tokens.number) {\n        var _index = t.numberLiteralFromRaw(token.value);\n\n        eatToken();\n        return _index;\n      } else {\n        throw function () {\n          return new Error(\"\\n\" + (0, _helperCodeFrame.codeFrameFromSource)(source, token.loc) + \"\\n\" + \"unknown export index\" + \", given \" + tokenToString(token));\n        }();\n      }\n    }\n\n    function lookaheadAndCheck() {\n      var len = arguments.length;\n\n      for (var i = 0; i < len; i++) {\n        var tokenAhead = tokensList[current + i];\n        var expectedToken = i < 0 || arguments.length <= i ? undefined : arguments[i];\n\n        if (tokenAhead.type === \"keyword\") {\n          if (isKeyword(tokenAhead, expectedToken) === false) {\n            return false;\n          }\n        } else if (expectedToken !== tokenAhead.type) {\n          return false;\n        }\n      }\n\n      return true;\n    } // TODO(sven): there is probably a better way to do this\n    // can refactor it if it get out of hands\n\n\n    function maybeIgnoreComment() {\n      if (typeof token === \"undefined\") {\n        // Ignore\n        return;\n      }\n\n      while (token.type === _tokenizer.tokens.comment) {\n        eatToken();\n\n        if (typeof token === \"undefined\") {\n          // Hit the end\n          break;\n        }\n      }\n    }\n    /**\n     * Parses a memory instruction\n     *\n     * WAST:\n     *\n     * memory:  ( memory <name>? <memory_sig> )\n     *          ( memory <name>? ( export <string> ) <...> )\n     *          ( memory <name>? ( import <string> <string> ) <memory_sig> )\n     *          ( memory <name>? ( export <string> )* ( data <string>* )\n     * memory_sig: <nat> <nat>?\n     *\n     */\n\n\n    function parseMemory() {\n      var id = t.identifier(getUniqueName(\"memory\"));\n      var limits = t.limit(0);\n\n      if (token.type === _tokenizer.tokens.string || token.type === _tokenizer.tokens.identifier) {\n        id = t.identifier(token.value);\n        eatToken();\n      } else {\n        id = t.withRaw(id, \"\"); // preserve anonymous\n      }\n      /**\n       * Maybe data\n       */\n\n\n      if (lookaheadAndCheck(_tokenizer.tokens.openParen, _tokenizer.keywords.data)) {\n        eatToken(); // (\n\n        eatToken(); // data\n        // TODO(sven): do something with the data collected here\n\n        var stringInitializer = token.value;\n        eatTokenOfType(_tokenizer.tokens.string); // Update limits accordingly\n\n        limits = t.limit(stringInitializer.length);\n        eatTokenOfType(_tokenizer.tokens.closeParen);\n      }\n      /**\n       * Maybe export\n       */\n\n\n      if (lookaheadAndCheck(_tokenizer.tokens.openParen, _tokenizer.keywords.export)) {\n        eatToken(); // (\n\n        eatToken(); // export\n\n        if (token.type !== _tokenizer.tokens.string) {\n          throw function () {\n            return new Error(\"\\n\" + (0, _helperCodeFrame.codeFrameFromSource)(source, token.loc) + \"\\n\" + \"Expected string in export\" + \", given \" + tokenToString(token));\n          }();\n        }\n\n        var _name = token.value;\n        eatToken();\n        state.registredExportedElements.push({\n          exportType: \"Memory\",\n          name: _name,\n          id: id\n        });\n        eatTokenOfType(_tokenizer.tokens.closeParen);\n      }\n      /**\n       * Memory signature\n       */\n\n\n      if (token.type === _tokenizer.tokens.number) {\n        limits = t.limit((0, _numberLiterals.parse32I)(token.value));\n        eatToken();\n\n        if (token.type === _tokenizer.tokens.number) {\n          limits.max = (0, _numberLiterals.parse32I)(token.value);\n          eatToken();\n        }\n      }\n\n      return t.memory(limits, id);\n    }\n    /**\n     * Parses a data section\n     * https://webassembly.github.io/spec/core/text/modules.html#data-segments\n     *\n     * WAST:\n     *\n     * data:  ( data <index>? <offset> <string> )\n     */\n\n\n    function parseData() {\n      // optional memory index\n      var memidx = 0;\n\n      if (token.type === _tokenizer.tokens.number) {\n        memidx = token.value;\n        eatTokenOfType(_tokenizer.tokens.number); // .\n      }\n\n      eatTokenOfType(_tokenizer.tokens.openParen);\n      var offset;\n\n      if (token.type === _tokenizer.tokens.valtype) {\n        eatTokenOfType(_tokenizer.tokens.valtype); // i32\n\n        eatTokenOfType(_tokenizer.tokens.dot); // .\n\n        if (token.value !== \"const\") {\n          throw new Error(\"constant expression required\");\n        }\n\n        eatTokenOfType(_tokenizer.tokens.name); // const\n\n        var numberLiteral = t.numberLiteralFromRaw(token.value, \"i32\");\n        offset = t.objectInstruction(\"const\", \"i32\", [numberLiteral]);\n        eatToken();\n        eatTokenOfType(_tokenizer.tokens.closeParen);\n      } else {\n        eatTokenOfType(_tokenizer.tokens.name); // get_global\n\n        var _numberLiteral = t.numberLiteralFromRaw(token.value, \"i32\");\n\n        offset = t.instruction(\"get_global\", [_numberLiteral]);\n        eatToken();\n        eatTokenOfType(_tokenizer.tokens.closeParen);\n      }\n\n      var byteArray = (0, _stringLiterals.parseString)(token.value);\n      eatToken(); // \"string\"\n\n      return t.data(t.memIndexLiteral(memidx), offset, t.byteArray(byteArray));\n    }\n    /**\n     * Parses a table instruction\n     *\n     * WAST:\n     *\n     * table:   ( table <name>? <table_type> )\n     *          ( table <name>? ( export <string> ) <...> )\n     *          ( table <name>? ( import <string> <string> ) <table_type> )\n     *          ( table <name>? ( export <string> )* <elem_type> ( elem <var>* ) )\n     *\n     * table_type:  <nat> <nat>? <elem_type>\n     * elem_type: anyfunc\n     *\n     * elem:    ( elem <var>? (offset <instr>* ) <var>* )\n     *          ( elem <var>? <expr> <var>* )\n     */\n\n\n    function parseTable() {\n      var name = t.identifier(getUniqueName(\"table\"));\n      var limit = t.limit(0);\n      var elemIndices = [];\n      var elemType = \"anyfunc\";\n\n      if (token.type === _tokenizer.tokens.string || token.type === _tokenizer.tokens.identifier) {\n        name = identifierFromToken(token);\n        eatToken();\n      } else {\n        name = t.withRaw(name, \"\"); // preserve anonymous\n      }\n\n      while (token.type !== _tokenizer.tokens.closeParen) {\n        /**\n         * Maybe export\n         */\n        if (lookaheadAndCheck(_tokenizer.tokens.openParen, _tokenizer.keywords.elem)) {\n          eatToken(); // (\n\n          eatToken(); // elem\n\n          while (token.type === _tokenizer.tokens.identifier) {\n            elemIndices.push(t.identifier(token.value));\n            eatToken();\n          }\n\n          eatTokenOfType(_tokenizer.tokens.closeParen);\n        } else if (lookaheadAndCheck(_tokenizer.tokens.openParen, _tokenizer.keywords.export)) {\n          eatToken(); // (\n\n          eatToken(); // export\n\n          if (token.type !== _tokenizer.tokens.string) {\n            throw function () {\n              return new Error(\"\\n\" + (0, _helperCodeFrame.codeFrameFromSource)(source, token.loc) + \"\\n\" + \"Expected string in export\" + \", given \" + tokenToString(token));\n            }();\n          }\n\n          var exportName = token.value;\n          eatToken();\n          state.registredExportedElements.push({\n            exportType: \"Table\",\n            name: exportName,\n            id: name\n          });\n          eatTokenOfType(_tokenizer.tokens.closeParen);\n        } else if (isKeyword(token, _tokenizer.keywords.anyfunc)) {\n          // It's the default value, we can ignore it\n          eatToken(); // anyfunc\n        } else if (token.type === _tokenizer.tokens.number) {\n          /**\n           * Table type\n           */\n          var min = parseInt(token.value);\n          eatToken();\n\n          if (token.type === _tokenizer.tokens.number) {\n            var max = parseInt(token.value);\n            eatToken();\n            limit = t.limit(min, max);\n          } else {\n            limit = t.limit(min);\n          }\n\n          eatToken();\n        } else {\n          throw function () {\n            return new Error(\"\\n\" + (0, _helperCodeFrame.codeFrameFromSource)(source, token.loc) + \"\\n\" + \"Unexpected token\" + \", given \" + tokenToString(token));\n          }();\n        }\n      }\n\n      if (elemIndices.length > 0) {\n        return t.table(elemType, limit, name, elemIndices);\n      } else {\n        return t.table(elemType, limit, name);\n      }\n    }\n    /**\n     * Parses an import statement\n     *\n     * WAST:\n     *\n     * import:  ( import <string> <string> <imkind> )\n     * imkind:  ( func <name>? <func_sig> )\n     *          ( global <name>? <global_sig> )\n     *          ( table <name>? <table_sig> )\n     *          ( memory <name>? <memory_sig> )\n     *\n     * global_sig: <type> | ( mut <type> )\n     */\n\n\n    function parseImport() {\n      if (token.type !== _tokenizer.tokens.string) {\n        throw new Error(\"Expected a string, \" + token.type + \" given.\");\n      }\n\n      var moduleName = token.value;\n      eatToken();\n\n      if (token.type !== _tokenizer.tokens.string) {\n        throw new Error(\"Expected a string, \" + token.type + \" given.\");\n      }\n\n      var name = token.value;\n      eatToken();\n      eatTokenOfType(_tokenizer.tokens.openParen);\n      var descr;\n\n      if (isKeyword(token, _tokenizer.keywords.func)) {\n        eatToken(); // keyword\n\n        var fnParams = [];\n        var fnResult = [];\n        var typeRef;\n        var fnName = t.identifier(getUniqueName(\"func\"));\n\n        if (token.type === _tokenizer.tokens.identifier) {\n          fnName = identifierFromToken(token);\n          eatToken();\n        }\n\n        while (token.type === _tokenizer.tokens.openParen) {\n          eatToken();\n\n          if (lookaheadAndCheck(_tokenizer.keywords.type) === true) {\n            eatToken();\n            typeRef = parseTypeReference();\n          } else if (lookaheadAndCheck(_tokenizer.keywords.param) === true) {\n            eatToken();\n            fnParams.push.apply(fnParams, _toConsumableArray(parseFuncParam()));\n          } else if (lookaheadAndCheck(_tokenizer.keywords.result) === true) {\n            eatToken();\n            fnResult.push.apply(fnResult, _toConsumableArray(parseFuncResult()));\n          } else {\n            throw function () {\n              return new Error(\"\\n\" + (0, _helperCodeFrame.codeFrameFromSource)(source, token.loc) + \"\\n\" + \"Unexpected token in import of type\" + \", given \" + tokenToString(token));\n            }();\n          }\n\n          eatTokenOfType(_tokenizer.tokens.closeParen);\n        }\n\n        if (typeof fnName === \"undefined\") {\n          throw new Error(\"Imported function must have a name\");\n        }\n\n        descr = t.funcImportDescr(fnName, typeRef !== undefined ? typeRef : t.signature(fnParams, fnResult));\n      } else if (isKeyword(token, _tokenizer.keywords.global)) {\n        eatToken(); // keyword\n\n        if (token.type === _tokenizer.tokens.openParen) {\n          eatToken(); // (\n\n          eatTokenOfType(_tokenizer.tokens.keyword); // mut keyword\n\n          var valtype = token.value;\n          eatToken();\n          descr = t.globalType(valtype, \"var\");\n          eatTokenOfType(_tokenizer.tokens.closeParen);\n        } else {\n          var _valtype = token.value;\n          eatTokenOfType(_tokenizer.tokens.valtype);\n          descr = t.globalType(_valtype, \"const\");\n        }\n      } else if (isKeyword(token, _tokenizer.keywords.memory) === true) {\n        eatToken(); // Keyword\n\n        descr = parseMemory();\n      } else if (isKeyword(token, _tokenizer.keywords.table) === true) {\n        eatToken(); // Keyword\n\n        descr = parseTable();\n      } else {\n        throw new Error(\"Unsupported import type: \" + tokenToString(token));\n      }\n\n      eatTokenOfType(_tokenizer.tokens.closeParen);\n      return t.moduleImport(moduleName, name, descr);\n    }\n    /**\n     * Parses a block instruction\n     *\n     * WAST:\n     *\n     * expr: ( block <name>? <block_sig> <instr>* )\n     * instr: block <name>? <block_sig> <instr>* end <name>?\n     * block_sig : ( result <type>* )*\n     *\n     */\n\n\n    function parseBlock() {\n      var label = t.identifier(getUniqueName(\"block\"));\n      var blockResult = null;\n      var instr = [];\n\n      if (token.type === _tokenizer.tokens.identifier) {\n        label = identifierFromToken(token);\n        eatToken();\n      } else {\n        label = t.withRaw(label, \"\"); // preserve anonymous\n      }\n\n      while (token.type === _tokenizer.tokens.openParen) {\n        eatToken();\n\n        if (lookaheadAndCheck(_tokenizer.keywords.result) === true) {\n          eatToken();\n          blockResult = token.value;\n          eatToken();\n        } else if (lookaheadAndCheck(_tokenizer.tokens.name) === true || lookaheadAndCheck(_tokenizer.tokens.valtype) === true || token.type === \"keyword\" // is any keyword\n        ) {\n            // Instruction\n            instr.push(parseFuncInstr());\n          } else {\n          throw function () {\n            return new Error(\"\\n\" + (0, _helperCodeFrame.codeFrameFromSource)(source, token.loc) + \"\\n\" + \"Unexpected token in block body of type\" + \", given \" + tokenToString(token));\n          }();\n        }\n\n        maybeIgnoreComment();\n        eatTokenOfType(_tokenizer.tokens.closeParen);\n      }\n\n      return t.blockInstruction(label, instr, blockResult);\n    }\n    /**\n     * Parses a if instruction\n     *\n     * WAST:\n     *\n     * expr:\n     * ( if <name>? <block_sig> ( then <instr>* ) ( else <instr>* )? )\n     * ( if <name>? <block_sig> <expr>+ ( then <instr>* ) ( else <instr>* )? )\n     *\n     * instr:\n     * if <name>? <block_sig> <instr>* end <name>?\n     * if <name>? <block_sig> <instr>* else <name>? <instr>* end <name>?\n     *\n     * block_sig : ( result <type>* )*\n     *\n     */\n\n\n    function parseIf() {\n      var blockResult = null;\n      var label = t.identifier(getUniqueName(\"if\"));\n      var testInstrs = [];\n      var consequent = [];\n      var alternate = [];\n\n      if (token.type === _tokenizer.tokens.identifier) {\n        label = identifierFromToken(token);\n        eatToken();\n      } else {\n        label = t.withRaw(label, \"\"); // preserve anonymous\n      }\n\n      while (token.type === _tokenizer.tokens.openParen) {\n        eatToken(); // (\n\n        /**\n         * Block signature\n         */\n\n        if (isKeyword(token, _tokenizer.keywords.result) === true) {\n          eatToken();\n          blockResult = token.value;\n          eatTokenOfType(_tokenizer.tokens.valtype);\n          eatTokenOfType(_tokenizer.tokens.closeParen);\n          continue;\n        }\n        /**\n         * Then\n         */\n\n\n        if (isKeyword(token, _tokenizer.keywords.then) === true) {\n          eatToken(); // then\n\n          while (token.type === _tokenizer.tokens.openParen) {\n            eatToken(); // Instruction\n\n            if (lookaheadAndCheck(_tokenizer.tokens.name) === true || lookaheadAndCheck(_tokenizer.tokens.valtype) === true || token.type === \"keyword\" // is any keyword\n            ) {\n                consequent.push(parseFuncInstr());\n              } else {\n              throw function () {\n                return new Error(\"\\n\" + (0, _helperCodeFrame.codeFrameFromSource)(source, token.loc) + \"\\n\" + \"Unexpected token in consequent body of type\" + \", given \" + tokenToString(token));\n              }();\n            }\n\n            eatTokenOfType(_tokenizer.tokens.closeParen);\n          }\n\n          eatTokenOfType(_tokenizer.tokens.closeParen);\n          continue;\n        }\n        /**\n         * Alternate\n         */\n\n\n        if (isKeyword(token, _tokenizer.keywords.else)) {\n          eatToken(); // else\n\n          while (token.type === _tokenizer.tokens.openParen) {\n            eatToken(); // Instruction\n\n            if (lookaheadAndCheck(_tokenizer.tokens.name) === true || lookaheadAndCheck(_tokenizer.tokens.valtype) === true || token.type === \"keyword\" // is any keyword\n            ) {\n                alternate.push(parseFuncInstr());\n              } else {\n              throw function () {\n                return new Error(\"\\n\" + (0, _helperCodeFrame.codeFrameFromSource)(source, token.loc) + \"\\n\" + \"Unexpected token in alternate body of type\" + \", given \" + tokenToString(token));\n              }();\n            }\n\n            eatTokenOfType(_tokenizer.tokens.closeParen);\n          }\n\n          eatTokenOfType(_tokenizer.tokens.closeParen);\n          continue;\n        }\n        /**\n         * Test instruction\n         */\n\n\n        if (lookaheadAndCheck(_tokenizer.tokens.name) === true || lookaheadAndCheck(_tokenizer.tokens.valtype) === true || token.type === \"keyword\" // is any keyword\n        ) {\n            testInstrs.push(parseFuncInstr());\n            eatTokenOfType(_tokenizer.tokens.closeParen);\n            continue;\n          }\n\n        throw function () {\n          return new Error(\"\\n\" + (0, _helperCodeFrame.codeFrameFromSource)(source, token.loc) + \"\\n\" + \"Unexpected token in if body\" + \", given \" + tokenToString(token));\n        }();\n      }\n\n      return t.ifInstruction(label, testInstrs, blockResult, consequent, alternate);\n    }\n    /**\n     * Parses a loop instruction\n     *\n     * WAT:\n     *\n     * blockinstr :: 'loop' I:label rt:resulttype (in:instr*) 'end' id?\n     *\n     * WAST:\n     *\n     * instr     :: loop <name>? <block_sig> <instr>* end <name>?\n     * expr      :: ( loop <name>? <block_sig> <instr>* )\n     * block_sig :: ( result <type>* )*\n     *\n     */\n\n\n    function parseLoop() {\n      var label = t.identifier(getUniqueName(\"loop\"));\n      var blockResult;\n      var instr = [];\n\n      if (token.type === _tokenizer.tokens.identifier) {\n        label = identifierFromToken(token);\n        eatToken();\n      } else {\n        label = t.withRaw(label, \"\"); // preserve anonymous\n      }\n\n      while (token.type === _tokenizer.tokens.openParen) {\n        eatToken();\n\n        if (lookaheadAndCheck(_tokenizer.keywords.result) === true) {\n          eatToken();\n          blockResult = token.value;\n          eatToken();\n        } else if (lookaheadAndCheck(_tokenizer.tokens.name) === true || lookaheadAndCheck(_tokenizer.tokens.valtype) === true || token.type === \"keyword\" // is any keyword\n        ) {\n            // Instruction\n            instr.push(parseFuncInstr());\n          } else {\n          throw function () {\n            return new Error(\"\\n\" + (0, _helperCodeFrame.codeFrameFromSource)(source, token.loc) + \"\\n\" + \"Unexpected token in loop body\" + \", given \" + tokenToString(token));\n          }();\n        }\n\n        eatTokenOfType(_tokenizer.tokens.closeParen);\n      }\n\n      return t.loopInstruction(label, blockResult, instr);\n    }\n\n    function parseCallIndirect() {\n      var typeRef;\n      var params = [];\n      var results = [];\n      var instrs = [];\n\n      while (token.type !== _tokenizer.tokens.closeParen) {\n        if (lookaheadAndCheck(_tokenizer.tokens.openParen, _tokenizer.keywords.type)) {\n          eatToken(); // (\n\n          eatToken(); // type\n\n          typeRef = parseTypeReference();\n        } else if (lookaheadAndCheck(_tokenizer.tokens.openParen, _tokenizer.keywords.param)) {\n          eatToken(); // (\n\n          eatToken(); // param\n\n          /**\n           * Params can be empty:\n           * (params)`\n           */\n\n          if (token.type !== _tokenizer.tokens.closeParen) {\n            params.push.apply(params, _toConsumableArray(parseFuncParam()));\n          }\n        } else if (lookaheadAndCheck(_tokenizer.tokens.openParen, _tokenizer.keywords.result)) {\n          eatToken(); // (\n\n          eatToken(); // result\n\n          /**\n           * Results can be empty:\n           * (result)`\n           */\n\n          if (token.type !== _tokenizer.tokens.closeParen) {\n            results.push.apply(results, _toConsumableArray(parseFuncResult()));\n          }\n        } else {\n          eatTokenOfType(_tokenizer.tokens.openParen);\n          instrs.push(parseFuncInstr());\n        }\n\n        eatTokenOfType(_tokenizer.tokens.closeParen);\n      }\n\n      return t.callIndirectInstruction(typeRef !== undefined ? typeRef : t.signature(params, results), instrs);\n    }\n    /**\n     * Parses an export instruction\n     *\n     * WAT:\n     *\n     * export:  ( export <string> <exkind> )\n     * exkind:  ( func <var> )\n     *          ( global <var> )\n     *          ( table <var> )\n     *          ( memory <var> )\n     * var:    <nat> | <name>\n     *\n     */\n\n\n    function parseExport() {\n      if (token.type !== _tokenizer.tokens.string) {\n        throw new Error(\"Expected string after export, got: \" + token.type);\n      }\n\n      var name = token.value;\n      eatToken();\n      var moduleExportDescr = parseModuleExportDescr();\n      return t.moduleExport(name, moduleExportDescr);\n    }\n\n    function parseModuleExportDescr() {\n      var startLoc = getStartLoc();\n      var type = \"\";\n      var index;\n      eatTokenOfType(_tokenizer.tokens.openParen);\n\n      while (token.type !== _tokenizer.tokens.closeParen) {\n        if (isKeyword(token, _tokenizer.keywords.func)) {\n          type = \"Func\";\n          eatToken();\n          index = parseExportIndex(token);\n        } else if (isKeyword(token, _tokenizer.keywords.table)) {\n          type = \"Table\";\n          eatToken();\n          index = parseExportIndex(token);\n        } else if (isKeyword(token, _tokenizer.keywords.global)) {\n          type = \"Global\";\n          eatToken();\n          index = parseExportIndex(token);\n        } else if (isKeyword(token, _tokenizer.keywords.memory)) {\n          type = \"Memory\";\n          eatToken();\n          index = parseExportIndex(token);\n        }\n\n        eatToken();\n      }\n\n      if (type === \"\") {\n        throw new Error(\"Unknown export type\");\n      }\n\n      if (index === undefined) {\n        throw new Error(\"Exported function must have a name\");\n      }\n\n      var node = t.moduleExportDescr(type, index);\n      var endLoc = getEndLoc();\n      eatTokenOfType(_tokenizer.tokens.closeParen);\n      return t.withLoc(node, endLoc, startLoc);\n    }\n\n    function parseModule() {\n      var name = null;\n      var isBinary = false;\n      var isQuote = false;\n      var moduleFields = [];\n\n      if (token.type === _tokenizer.tokens.identifier) {\n        name = token.value;\n        eatToken();\n      }\n\n      if (hasPlugin(\"wast\") && token.type === _tokenizer.tokens.name && token.value === \"binary\") {\n        eatToken();\n        isBinary = true;\n      }\n\n      if (hasPlugin(\"wast\") && token.type === _tokenizer.tokens.name && token.value === \"quote\") {\n        eatToken();\n        isQuote = true;\n      }\n\n      if (isBinary === true) {\n        var blob = [];\n\n        while (token.type === _tokenizer.tokens.string) {\n          blob.push(token.value);\n          eatToken();\n          maybeIgnoreComment();\n        }\n\n        eatTokenOfType(_tokenizer.tokens.closeParen);\n        return t.binaryModule(name, blob);\n      }\n\n      if (isQuote === true) {\n        var string = [];\n\n        while (token.type === _tokenizer.tokens.string) {\n          string.push(token.value);\n          eatToken();\n        }\n\n        eatTokenOfType(_tokenizer.tokens.closeParen);\n        return t.quoteModule(name, string);\n      }\n\n      while (token.type !== _tokenizer.tokens.closeParen) {\n        moduleFields.push(walk());\n\n        if (state.registredExportedElements.length > 0) {\n          state.registredExportedElements.forEach(function (decl) {\n            moduleFields.push(t.moduleExport(decl.name, t.moduleExportDescr(decl.exportType, decl.id)));\n          });\n          state.registredExportedElements = [];\n        }\n\n        token = tokensList[current];\n      }\n\n      eatTokenOfType(_tokenizer.tokens.closeParen);\n      return t.module(name, moduleFields);\n    }\n    /**\n     * Parses the arguments of an instruction\n     */\n\n\n    function parseFuncInstrArguments(signature) {\n      var args = [];\n      var namedArgs = {};\n      var signaturePtr = 0;\n\n      while (token.type === _tokenizer.tokens.name || isKeyword(token, _tokenizer.keywords.offset)) {\n        var key = token.value;\n        eatToken();\n        eatTokenOfType(_tokenizer.tokens.equal);\n        var value = void 0;\n\n        if (token.type === _tokenizer.tokens.number) {\n          value = t.numberLiteralFromRaw(token.value);\n        } else {\n          throw new Error(\"Unexpected type for argument: \" + token.type);\n        }\n\n        namedArgs[key] = value;\n        eatToken();\n      } // $FlowIgnore\n\n\n      var signatureLength = signature.vector ? Infinity : signature.length;\n\n      while (token.type !== _tokenizer.tokens.closeParen && ( // $FlowIgnore\n      token.type === _tokenizer.tokens.openParen || signaturePtr < signatureLength)) {\n        if (token.type === _tokenizer.tokens.identifier) {\n          args.push(t.identifier(token.value));\n          eatToken();\n        } else if (token.type === _tokenizer.tokens.valtype) {\n          // Handle locals\n          args.push(t.valtypeLiteral(token.value));\n          eatToken();\n        } else if (token.type === _tokenizer.tokens.string) {\n          args.push(t.stringLiteral(token.value));\n          eatToken();\n        } else if (token.type === _tokenizer.tokens.number) {\n          args.push( // TODO(sven): refactor the type signature handling\n          // https://github.com/xtuc/webassemblyjs/pull/129 is a good start\n          t.numberLiteralFromRaw(token.value, // $FlowIgnore\n          signature[signaturePtr] || \"f64\")); // $FlowIgnore\n\n          if (!signature.vector) {\n            ++signaturePtr;\n          }\n\n          eatToken();\n        } else if (token.type === _tokenizer.tokens.openParen) {\n          /**\n           * Maybe some nested instructions\n           */\n          eatToken(); // Instruction\n\n          if (lookaheadAndCheck(_tokenizer.tokens.name) === true || lookaheadAndCheck(_tokenizer.tokens.valtype) === true || token.type === \"keyword\" // is any keyword\n          ) {\n              // $FlowIgnore\n              args.push(parseFuncInstr());\n            } else {\n            throw function () {\n              return new Error(\"\\n\" + (0, _helperCodeFrame.codeFrameFromSource)(source, token.loc) + \"\\n\" + \"Unexpected token in nested instruction\" + \", given \" + tokenToString(token));\n            }();\n          }\n\n          if (token.type === _tokenizer.tokens.closeParen) {\n            eatToken();\n          }\n        } else {\n          throw function () {\n            return new Error(\"\\n\" + (0, _helperCodeFrame.codeFrameFromSource)(source, token.loc) + \"\\n\" + \"Unexpected token in instruction argument\" + \", given \" + tokenToString(token));\n          }();\n        }\n      }\n\n      return {\n        args: args,\n        namedArgs: namedArgs\n      };\n    }\n    /**\n     * Parses an instruction\n     *\n     * WAT:\n     *\n     * instr      :: plaininst\n     *               blockinstr\n     *\n     * blockinstr :: 'block' I:label rt:resulttype (in:instr*) 'end' id?\n     *               'loop' I:label rt:resulttype (in:instr*) 'end' id?\n     *               'if' I:label rt:resulttype (in:instr*) 'else' id? (in2:intr*) 'end' id?\n     *\n     * plaininst  :: 'unreachable'\n     *               'nop'\n     *               'br' l:labelidx\n     *               'br_if' l:labelidx\n     *               'br_table' l*:vec(labelidx) ln:labelidx\n     *               'return'\n     *               'call' x:funcidx\n     *               'call_indirect' x, I:typeuse\n     *\n     * WAST:\n     *\n     * instr:\n     *   <expr>\n     *   <op>\n     *   block <name>? <block_sig> <instr>* end <name>?\n     *   loop <name>? <block_sig> <instr>* end <name>?\n     *   if <name>? <block_sig> <instr>* end <name>?\n     *   if <name>? <block_sig> <instr>* else <name>? <instr>* end <name>?\n     *\n     * expr:\n     *   ( <op> )\n     *   ( <op> <expr>+ )\n     *   ( block <name>? <block_sig> <instr>* )\n     *   ( loop <name>? <block_sig> <instr>* )\n     *   ( if <name>? <block_sig> ( then <instr>* ) ( else <instr>* )? )\n     *   ( if <name>? <block_sig> <expr>+ ( then <instr>* ) ( else <instr>* )? )\n     *\n     * op:\n     *   unreachable\n     *   nop\n     *   br <var>\n     *   br_if <var>\n     *   br_table <var>+\n     *   return\n     *   call <var>\n     *   call_indirect <func_sig>\n     *   drop\n     *   select\n     *   get_local <var>\n     *   set_local <var>\n     *   tee_local <var>\n     *   get_global <var>\n     *   set_global <var>\n     *   <type>.load((8|16|32)_<sign>)? <offset>? <align>?\n     *   <type>.store(8|16|32)? <offset>? <align>?\n     *   current_memory\n     *   grow_memory\n     *   <type>.const <value>\n     *   <type>.<unop>\n     *   <type>.<binop>\n     *   <type>.<testop>\n     *   <type>.<relop>\n     *   <type>.<cvtop>/<type>\n     *\n     * func_type:   ( type <var> )? <param>* <result>*\n     */\n\n\n    function parseFuncInstr() {\n      var startLoc = getStartLoc();\n      maybeIgnoreComment();\n      /**\n       * A simple instruction\n       */\n\n      if (token.type === _tokenizer.tokens.name || token.type === _tokenizer.tokens.valtype) {\n        var _name2 = token.value;\n        var object;\n        eatToken();\n\n        if (token.type === _tokenizer.tokens.dot) {\n          object = _name2;\n          eatToken();\n\n          if (token.type !== _tokenizer.tokens.name) {\n            throw new TypeError(\"Unknown token: \" + token.type + \", name expected\");\n          }\n\n          _name2 = token.value;\n          eatToken();\n        }\n\n        if (token.type === _tokenizer.tokens.closeParen) {\n          var _endLoc = token.loc.end;\n\n          if (typeof object === \"undefined\") {\n            return t.withLoc(t.instruction(_name2), _endLoc, startLoc);\n          } else {\n            return t.withLoc(t.objectInstruction(_name2, object, []), _endLoc, startLoc);\n          }\n        }\n\n        var signature = t.signatureForOpcode(object || \"\", _name2);\n\n        var _parseFuncInstrArgume = parseFuncInstrArguments(signature),\n            _args = _parseFuncInstrArgume.args,\n            _namedArgs = _parseFuncInstrArgume.namedArgs;\n\n        var endLoc = token.loc.end;\n\n        if (typeof object === \"undefined\") {\n          return t.withLoc(t.instruction(_name2, _args, _namedArgs), endLoc, startLoc);\n        } else {\n          return t.withLoc(t.objectInstruction(_name2, object, _args, _namedArgs), endLoc, startLoc);\n        }\n      } else if (isKeyword(token, _tokenizer.keywords.loop)) {\n        /**\n         * Else a instruction with a keyword (loop or block)\n         */\n        eatToken(); // keyword\n\n        return parseLoop();\n      } else if (isKeyword(token, _tokenizer.keywords.block)) {\n        eatToken(); // keyword\n\n        return parseBlock();\n      } else if (isKeyword(token, _tokenizer.keywords.call_indirect)) {\n        eatToken(); // keyword\n\n        return parseCallIndirect();\n      } else if (isKeyword(token, _tokenizer.keywords.call)) {\n        eatToken(); // keyword\n\n        var index;\n\n        if (token.type === _tokenizer.tokens.identifier) {\n          index = identifierFromToken(token);\n          eatToken();\n        } else if (token.type === _tokenizer.tokens.number) {\n          index = t.indexLiteral(token.value);\n          eatToken();\n        }\n\n        var instrArgs = []; // Nested instruction\n\n        while (token.type === _tokenizer.tokens.openParen) {\n          eatToken();\n          instrArgs.push(parseFuncInstr());\n          eatTokenOfType(_tokenizer.tokens.closeParen);\n        }\n\n        if (typeof index === \"undefined\") {\n          throw new Error(\"Missing argument in call instruciton\");\n        }\n\n        if (instrArgs.length > 0) {\n          return t.callInstruction(index, instrArgs);\n        } else {\n          return t.callInstruction(index);\n        }\n      } else if (isKeyword(token, _tokenizer.keywords.if)) {\n        eatToken(); // Keyword\n\n        return parseIf();\n      } else if (isKeyword(token, _tokenizer.keywords.module) && hasPlugin(\"wast\")) {\n        eatToken(); // In WAST you can have a module as an instruction's argument\n        // we will cast it into a instruction to not break the flow\n        // $FlowIgnore\n\n        var module = parseModule();\n        return module;\n      } else {\n        throw function () {\n          return new Error(\"\\n\" + (0, _helperCodeFrame.codeFrameFromSource)(source, token.loc) + \"\\n\" + \"Unexpected instruction in function body\" + \", given \" + tokenToString(token));\n        }();\n      }\n    }\n    /*\n     * Parses a function\n     *\n     * WAT:\n     *\n     * functype :: ( 'func' t1:vec(param) t2:vec(result) )\n     * param    :: ( 'param' id? t:valtype )\n     * result   :: ( 'result' t:valtype )\n     *\n     * WAST:\n     *\n     * func     :: ( func <name>? <func_sig> <local>* <instr>* )\n     *             ( func <name>? ( export <string> ) <...> )\n     *             ( func <name>? ( import <string> <string> ) <func_sig> )\n     * func_sig :: ( type <var> )? <param>* <result>*\n     * param    :: ( param <type>* ) | ( param <name> <type> )\n     * result   :: ( result <type>* )\n     * local    :: ( local <type>* ) | ( local <name> <type> )\n     *\n     */\n\n\n    function parseFunc() {\n      var fnName = t.identifier(getUniqueName(\"func\"));\n      var typeRef;\n      var fnBody = [];\n      var fnParams = [];\n      var fnResult = []; // name\n\n      if (token.type === _tokenizer.tokens.identifier) {\n        fnName = identifierFromToken(token);\n        eatToken();\n      } else {\n        fnName = t.withRaw(fnName, \"\"); // preserve anonymous\n      }\n\n      maybeIgnoreComment();\n\n      while (token.type === _tokenizer.tokens.openParen || token.type === _tokenizer.tokens.name || token.type === _tokenizer.tokens.valtype) {\n        // Instructions without parens\n        if (token.type === _tokenizer.tokens.name || token.type === _tokenizer.tokens.valtype) {\n          fnBody.push(parseFuncInstr());\n          continue;\n        }\n\n        eatToken();\n\n        if (lookaheadAndCheck(_tokenizer.keywords.param) === true) {\n          eatToken();\n          fnParams.push.apply(fnParams, _toConsumableArray(parseFuncParam()));\n        } else if (lookaheadAndCheck(_tokenizer.keywords.result) === true) {\n          eatToken();\n          fnResult.push.apply(fnResult, _toConsumableArray(parseFuncResult()));\n        } else if (lookaheadAndCheck(_tokenizer.keywords.export) === true) {\n          eatToken();\n          parseFuncExport(fnName);\n        } else if (lookaheadAndCheck(_tokenizer.keywords.type) === true) {\n          eatToken();\n          typeRef = parseTypeReference();\n        } else if (lookaheadAndCheck(_tokenizer.tokens.name) === true || lookaheadAndCheck(_tokenizer.tokens.valtype) === true || token.type === \"keyword\" // is any keyword\n        ) {\n            // Instruction\n            fnBody.push(parseFuncInstr());\n          } else {\n          throw function () {\n            return new Error(\"\\n\" + (0, _helperCodeFrame.codeFrameFromSource)(source, token.loc) + \"\\n\" + \"Unexpected token in func body\" + \", given \" + tokenToString(token));\n          }();\n        }\n\n        eatTokenOfType(_tokenizer.tokens.closeParen);\n      }\n\n      return t.func(fnName, typeRef !== undefined ? typeRef : t.signature(fnParams, fnResult), fnBody);\n    }\n    /**\n     * Parses shorthand export in func\n     *\n     * export :: ( export <string> )\n     */\n\n\n    function parseFuncExport(funcId) {\n      if (token.type !== _tokenizer.tokens.string) {\n        throw function () {\n          return new Error(\"\\n\" + (0, _helperCodeFrame.codeFrameFromSource)(source, token.loc) + \"\\n\" + \"Function export expected a string\" + \", given \" + tokenToString(token));\n        }();\n      }\n\n      var name = token.value;\n      eatToken();\n      /**\n       * Func export shorthand, we trait it as a syntaxic sugar.\n       * A export ModuleField will be added later.\n       *\n       * We give the anonymous function a generated name and export it.\n       */\n\n      var id = t.identifier(funcId.value);\n      state.registredExportedElements.push({\n        exportType: \"Func\",\n        name: name,\n        id: id\n      });\n    }\n    /**\n     * Parses a type instruction\n     *\n     * WAST:\n     *\n     * typedef: ( type <name>? ( func <param>* <result>* ) )\n     */\n\n\n    function parseType() {\n      var id;\n      var params = [];\n      var result = [];\n\n      if (token.type === _tokenizer.tokens.identifier) {\n        id = identifierFromToken(token);\n        eatToken();\n      }\n\n      if (lookaheadAndCheck(_tokenizer.tokens.openParen, _tokenizer.keywords.func)) {\n        eatToken(); // (\n\n        eatToken(); // func\n\n        if (token.type === _tokenizer.tokens.closeParen) {\n          eatToken(); // function with an empty signature, we can abort here\n\n          return t.typeInstruction(id, t.signature([], []));\n        }\n\n        if (lookaheadAndCheck(_tokenizer.tokens.openParen, _tokenizer.keywords.param)) {\n          eatToken(); // (\n\n          eatToken(); // param\n\n          params = parseFuncParam();\n          eatTokenOfType(_tokenizer.tokens.closeParen);\n        }\n\n        if (lookaheadAndCheck(_tokenizer.tokens.openParen, _tokenizer.keywords.result)) {\n          eatToken(); // (\n\n          eatToken(); // result\n\n          result = parseFuncResult();\n          eatTokenOfType(_tokenizer.tokens.closeParen);\n        }\n\n        eatTokenOfType(_tokenizer.tokens.closeParen);\n      }\n\n      return t.typeInstruction(id, t.signature(params, result));\n    }\n    /**\n     * Parses a function result\n     *\n     * WAST:\n     *\n     * result :: ( result <type>* )\n     */\n\n\n    function parseFuncResult() {\n      var results = [];\n\n      while (token.type !== _tokenizer.tokens.closeParen) {\n        if (token.type !== _tokenizer.tokens.valtype) {\n          throw function () {\n            return new Error(\"\\n\" + (0, _helperCodeFrame.codeFrameFromSource)(source, token.loc) + \"\\n\" + \"Unexpected token in func result\" + \", given \" + tokenToString(token));\n          }();\n        }\n\n        var valtype = token.value;\n        eatToken();\n        results.push(valtype);\n      }\n\n      return results;\n    }\n    /**\n     * Parses a type reference\n     *\n     */\n\n\n    function parseTypeReference() {\n      var ref;\n\n      if (token.type === _tokenizer.tokens.identifier) {\n        ref = identifierFromToken(token);\n        eatToken();\n      } else if (token.type === _tokenizer.tokens.number) {\n        ref = t.numberLiteralFromRaw(token.value);\n        eatToken();\n      }\n\n      return ref;\n    }\n    /**\n     * Parses a global instruction\n     *\n     * WAST:\n     *\n     * global:  ( global <name>? <global_sig> <instr>* )\n     *          ( global <name>? ( export <string> ) <...> )\n     *          ( global <name>? ( import <string> <string> ) <global_sig> )\n     *\n     * global_sig: <type> | ( mut <type> )\n     *\n     */\n\n\n    function parseGlobal() {\n      var name = t.identifier(getUniqueName(\"global\"));\n      var type; // Keep informations in case of a shorthand import\n\n      var importing = null;\n      maybeIgnoreComment();\n\n      if (token.type === _tokenizer.tokens.identifier) {\n        name = identifierFromToken(token);\n        eatToken();\n      } else {\n        name = t.withRaw(name, \"\"); // preserve anonymous\n      }\n      /**\n       * maybe export\n       */\n\n\n      if (lookaheadAndCheck(_tokenizer.tokens.openParen, _tokenizer.keywords.export)) {\n        eatToken(); // (\n\n        eatToken(); // export\n\n        var exportName = token.value;\n        eatTokenOfType(_tokenizer.tokens.string);\n        state.registredExportedElements.push({\n          exportType: \"Global\",\n          name: exportName,\n          id: name\n        });\n        eatTokenOfType(_tokenizer.tokens.closeParen);\n      }\n      /**\n       * maybe import\n       */\n\n\n      if (lookaheadAndCheck(_tokenizer.tokens.openParen, _tokenizer.keywords.import)) {\n        eatToken(); // (\n\n        eatToken(); // import\n\n        var moduleName = token.value;\n        eatTokenOfType(_tokenizer.tokens.string);\n        var _name3 = token.value;\n        eatTokenOfType(_tokenizer.tokens.string);\n        importing = {\n          module: moduleName,\n          name: _name3,\n          descr: undefined\n        };\n        eatTokenOfType(_tokenizer.tokens.closeParen);\n      }\n      /**\n       * global_sig\n       */\n\n\n      if (token.type === _tokenizer.tokens.valtype) {\n        type = t.globalType(token.value, \"const\");\n        eatToken();\n      } else if (token.type === _tokenizer.tokens.openParen) {\n        eatToken(); // (\n\n        if (isKeyword(token, _tokenizer.keywords.mut) === false) {\n          throw function () {\n            return new Error(\"\\n\" + (0, _helperCodeFrame.codeFrameFromSource)(source, token.loc) + \"\\n\" + \"Unsupported global type, expected mut\" + \", given \" + tokenToString(token));\n          }();\n        }\n\n        eatToken(); // mut\n\n        type = t.globalType(token.value, \"var\");\n        eatToken();\n        eatTokenOfType(_tokenizer.tokens.closeParen);\n      }\n\n      if (type === undefined) {\n        throw function () {\n          return new Error(\"\\n\" + (0, _helperCodeFrame.codeFrameFromSource)(source, token.loc) + \"\\n\" + \"Could not determine global type\" + \", given \" + tokenToString(token));\n        }();\n      }\n\n      maybeIgnoreComment();\n      var init = [];\n\n      if (importing != null) {\n        importing.descr = type;\n        init.push(t.moduleImport(importing.module, importing.name, importing.descr));\n      }\n      /**\n       * instr*\n       */\n\n\n      while (token.type === _tokenizer.tokens.openParen) {\n        eatToken();\n        init.push(parseFuncInstr());\n        eatTokenOfType(_tokenizer.tokens.closeParen);\n      }\n\n      return t.global(type, init, name);\n    }\n    /**\n     * Parses a function param\n     *\n     * WAST:\n     *\n     * param    :: ( param <type>* ) | ( param <name> <type> )\n     */\n\n\n    function parseFuncParam() {\n      var params = [];\n      var id;\n      var valtype;\n\n      if (token.type === _tokenizer.tokens.identifier) {\n        id = token.value;\n        eatToken();\n      }\n\n      if (token.type === _tokenizer.tokens.valtype) {\n        valtype = token.value;\n        eatToken();\n        params.push({\n          id: id,\n          valtype: valtype\n        });\n        /**\n         * Shorthand notation for multiple anonymous parameters\n         * @see https://webassembly.github.io/spec/core/text/types.html#function-types\n         * @see https://github.com/xtuc/webassemblyjs/issues/6\n         */\n\n        if (id === undefined) {\n          while (token.type === _tokenizer.tokens.valtype) {\n            valtype = token.value;\n            eatToken();\n            params.push({\n              id: undefined,\n              valtype: valtype\n            });\n          }\n        }\n      } else {// ignore\n      }\n\n      return params;\n    }\n    /**\n     * Parses an element segments instruction\n     *\n     * WAST:\n     *\n     * elem:    ( elem <var>? (offset <instr>* ) <var>* )\n     *          ( elem <var>? <expr> <var>* )\n     *\n     * var:    <nat> | <name>\n     */\n\n\n    function parseElem() {\n      var tableIndex = t.indexLiteral(0);\n      var offset = [];\n      var funcs = [];\n\n      if (token.type === _tokenizer.tokens.identifier) {\n        tableIndex = identifierFromToken(token);\n        eatToken();\n      }\n\n      if (token.type === _tokenizer.tokens.number) {\n        tableIndex = t.indexLiteral(token.value);\n        eatToken();\n      }\n\n      while (token.type !== _tokenizer.tokens.closeParen) {\n        if (lookaheadAndCheck(_tokenizer.tokens.openParen, _tokenizer.keywords.offset)) {\n          eatToken(); // (\n\n          eatToken(); // offset\n\n          while (token.type !== _tokenizer.tokens.closeParen) {\n            eatTokenOfType(_tokenizer.tokens.openParen);\n            offset.push(parseFuncInstr());\n            eatTokenOfType(_tokenizer.tokens.closeParen);\n          }\n\n          eatTokenOfType(_tokenizer.tokens.closeParen);\n        } else if (token.type === _tokenizer.tokens.identifier) {\n          funcs.push(t.identifier(token.value));\n          eatToken();\n        } else if (token.type === _tokenizer.tokens.number) {\n          funcs.push(t.indexLiteral(token.value));\n          eatToken();\n        } else if (token.type === _tokenizer.tokens.openParen) {\n          eatToken(); // (\n\n          offset.push(parseFuncInstr());\n          eatTokenOfType(_tokenizer.tokens.closeParen);\n        } else {\n          throw function () {\n            return new Error(\"\\n\" + (0, _helperCodeFrame.codeFrameFromSource)(source, token.loc) + \"\\n\" + \"Unsupported token in elem\" + \", given \" + tokenToString(token));\n          }();\n        }\n      }\n\n      return t.elem(tableIndex, offset, funcs);\n    }\n    /**\n     * Parses the start instruction in a module\n     *\n     * WAST:\n     *\n     * start:   ( start <var> )\n     * var:    <nat> | <name>\n     *\n     * WAT:\n     * start ::= ( start  x:funcidx )\n     */\n\n\n    function parseStart() {\n      if (token.type === _tokenizer.tokens.identifier) {\n        var index = identifierFromToken(token);\n        eatToken();\n        return t.start(index);\n      }\n\n      if (token.type === _tokenizer.tokens.number) {\n        var _index2 = t.indexLiteral(token.value);\n\n        eatToken();\n        return t.start(_index2);\n      }\n\n      throw new Error(\"Unknown start, token: \" + tokenToString(token));\n    }\n\n    if (token.type === _tokenizer.tokens.openParen) {\n      eatToken();\n      var startLoc = getStartLoc();\n\n      if (isKeyword(token, _tokenizer.keywords.export)) {\n        eatToken();\n        var node = parseExport();\n\n        var _endLoc2 = getEndLoc();\n\n        return t.withLoc(node, _endLoc2, startLoc);\n      }\n\n      if (isKeyword(token, _tokenizer.keywords.loop)) {\n        eatToken();\n\n        var _node = parseLoop();\n\n        var _endLoc3 = getEndLoc();\n\n        return t.withLoc(_node, _endLoc3, startLoc);\n      }\n\n      if (isKeyword(token, _tokenizer.keywords.func)) {\n        eatToken();\n\n        var _node2 = parseFunc();\n\n        var _endLoc4 = getEndLoc();\n\n        maybeIgnoreComment();\n        eatTokenOfType(_tokenizer.tokens.closeParen);\n        return t.withLoc(_node2, _endLoc4, startLoc);\n      }\n\n      if (isKeyword(token, _tokenizer.keywords.module)) {\n        eatToken();\n\n        var _node3 = parseModule();\n\n        var _endLoc5 = getEndLoc();\n\n        return t.withLoc(_node3, _endLoc5, startLoc);\n      }\n\n      if (isKeyword(token, _tokenizer.keywords.import)) {\n        eatToken();\n\n        var _node4 = parseImport();\n\n        var _endLoc6 = getEndLoc();\n\n        eatTokenOfType(_tokenizer.tokens.closeParen);\n        return t.withLoc(_node4, _endLoc6, startLoc);\n      }\n\n      if (isKeyword(token, _tokenizer.keywords.block)) {\n        eatToken();\n\n        var _node5 = parseBlock();\n\n        var _endLoc7 = getEndLoc();\n\n        eatTokenOfType(_tokenizer.tokens.closeParen);\n        return t.withLoc(_node5, _endLoc7, startLoc);\n      }\n\n      if (isKeyword(token, _tokenizer.keywords.memory)) {\n        eatToken();\n\n        var _node6 = parseMemory();\n\n        var _endLoc8 = getEndLoc();\n\n        eatTokenOfType(_tokenizer.tokens.closeParen);\n        return t.withLoc(_node6, _endLoc8, startLoc);\n      }\n\n      if (isKeyword(token, _tokenizer.keywords.data)) {\n        eatToken();\n\n        var _node7 = parseData();\n\n        var _endLoc9 = getEndLoc();\n\n        eatTokenOfType(_tokenizer.tokens.closeParen);\n        return t.withLoc(_node7, _endLoc9, startLoc);\n      }\n\n      if (isKeyword(token, _tokenizer.keywords.table)) {\n        eatToken();\n\n        var _node8 = parseTable();\n\n        var _endLoc10 = getEndLoc();\n\n        eatTokenOfType(_tokenizer.tokens.closeParen);\n        return t.withLoc(_node8, _endLoc10, startLoc);\n      }\n\n      if (isKeyword(token, _tokenizer.keywords.global)) {\n        eatToken();\n\n        var _node9 = parseGlobal();\n\n        var _endLoc11 = getEndLoc();\n\n        eatTokenOfType(_tokenizer.tokens.closeParen);\n        return t.withLoc(_node9, _endLoc11, startLoc);\n      }\n\n      if (isKeyword(token, _tokenizer.keywords.type)) {\n        eatToken();\n\n        var _node10 = parseType();\n\n        var _endLoc12 = getEndLoc();\n\n        eatTokenOfType(_tokenizer.tokens.closeParen);\n        return t.withLoc(_node10, _endLoc12, startLoc);\n      }\n\n      if (isKeyword(token, _tokenizer.keywords.start)) {\n        eatToken();\n\n        var _node11 = parseStart();\n\n        var _endLoc13 = getEndLoc();\n\n        eatTokenOfType(_tokenizer.tokens.closeParen);\n        return t.withLoc(_node11, _endLoc13, startLoc);\n      }\n\n      if (isKeyword(token, _tokenizer.keywords.elem)) {\n        eatToken();\n\n        var _node12 = parseElem();\n\n        var _endLoc14 = getEndLoc();\n\n        eatTokenOfType(_tokenizer.tokens.closeParen);\n        return t.withLoc(_node12, _endLoc14, startLoc);\n      }\n\n      var instruction = parseFuncInstr();\n      var endLoc = getEndLoc();\n      maybeIgnoreComment();\n\n      if (_typeof(instruction) === \"object\") {\n        if (typeof token !== \"undefined\") {\n          eatTokenOfType(_tokenizer.tokens.closeParen);\n        }\n\n        return t.withLoc(instruction, endLoc, startLoc);\n      }\n    }\n\n    if (token.type === _tokenizer.tokens.comment) {\n      var _startLoc = getStartLoc();\n\n      var builder = token.opts.type === \"leading\" ? t.leadingComment : t.blockComment;\n\n      var _node13 = builder(token.value);\n\n      eatToken(); // comment\n\n      var _endLoc15 = getEndLoc();\n\n      return t.withLoc(_node13, _endLoc15, _startLoc);\n    }\n\n    throw function () {\n      return new Error(\"\\n\" + (0, _helperCodeFrame.codeFrameFromSource)(source, token.loc) + \"\\n\" + \"Unknown token\" + \", given \" + tokenToString(token));\n    }();\n  }\n\n  var body = [];\n\n  while (current < tokensList.length) {\n    body.push(walk());\n  }\n\n  return t.program(body);\n}","\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.parse32F = parse32F;\nexports.parse64F = parse64F;\nexports.parse32I = parse32I;\nexports.parseU32 = parseU32;\nexports.parse64I = parse64I;\nexports.isInfLiteral = isInfLiteral;\nexports.isNanLiteral = isNanLiteral;\n\nvar _long = _interopRequireDefault(require(\"@xtuc/long\"));\n\nvar _floatingPointHexParser = _interopRequireDefault(require(\"@webassemblyjs/floating-point-hex-parser\"));\n\nvar _helperApiError = require(\"@webassemblyjs/helper-api-error\");\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction parse32F(sourceString) {\n  if (isHexLiteral(sourceString)) {\n    return (0, _floatingPointHexParser.default)(sourceString);\n  }\n\n  if (isInfLiteral(sourceString)) {\n    return sourceString[0] === \"-\" ? -1 : 1;\n  }\n\n  if (isNanLiteral(sourceString)) {\n    return (sourceString[0] === \"-\" ? -1 : 1) * (sourceString.includes(\":\") ? parseInt(sourceString.substring(sourceString.indexOf(\":\") + 1), 16) : 0x400000);\n  }\n\n  return parseFloat(sourceString);\n}\n\nfunction parse64F(sourceString) {\n  if (isHexLiteral(sourceString)) {\n    return (0, _floatingPointHexParser.default)(sourceString);\n  }\n\n  if (isInfLiteral(sourceString)) {\n    return sourceString[0] === \"-\" ? -1 : 1;\n  }\n\n  if (isNanLiteral(sourceString)) {\n    return (sourceString[0] === \"-\" ? -1 : 1) * (sourceString.includes(\":\") ? parseInt(sourceString.substring(sourceString.indexOf(\":\") + 1), 16) : 0x8000000000000);\n  }\n\n  if (isHexLiteral(sourceString)) {\n    return (0, _floatingPointHexParser.default)(sourceString);\n  }\n\n  return parseFloat(sourceString);\n}\n\nfunction parse32I(sourceString) {\n  var value = 0;\n\n  if (isHexLiteral(sourceString)) {\n    value = ~~parseInt(sourceString, 16);\n  } else if (isDecimalExponentLiteral(sourceString)) {\n    throw new Error(\"This number literal format is yet to be implemented.\");\n  } else {\n    value = parseInt(sourceString, 10);\n  }\n\n  return value;\n}\n\nfunction parseU32(sourceString) {\n  var value = parse32I(sourceString);\n\n  if (value < 0) {\n    throw new _helperApiError.CompileError(\"Illegal value for u32: \" + sourceString);\n  }\n\n  return value;\n}\n\nfunction parse64I(sourceString) {\n  var long;\n\n  if (isHexLiteral(sourceString)) {\n    long = _long.default.fromString(sourceString, false, 16);\n  } else if (isDecimalExponentLiteral(sourceString)) {\n    throw new Error(\"This number literal format is yet to be implemented.\");\n  } else {\n    long = _long.default.fromString(sourceString);\n  }\n\n  return {\n    high: long.high,\n    low: long.low\n  };\n}\n\nvar NAN_WORD = /^\\+?-?nan/;\nvar INF_WORD = /^\\+?-?inf/;\n\nfunction isInfLiteral(sourceString) {\n  return INF_WORD.test(sourceString.toLowerCase());\n}\n\nfunction isNanLiteral(sourceString) {\n  return NAN_WORD.test(sourceString.toLowerCase());\n}\n\nfunction isDecimalExponentLiteral(sourceString) {\n  return !isHexLiteral(sourceString) && sourceString.toUpperCase().includes(\"E\");\n}\n\nfunction isHexLiteral(sourceString) {\n  return sourceString.substring(0, 2).toUpperCase() === \"0X\" || sourceString.substring(0, 3).toUpperCase() === \"-0X\";\n}","\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.parseString = parseString;\n// string literal characters cannot contain control codes\nvar CONTROL_CODES = [0, // null\n7, // bell\n8, // backspace\n9, // horizontal\n10, // line feed\n11, // vertical tab\n12, // form feed\n13, // carriage return\n26, // Control-Z\n27, // escape\n127 // delete\n]; // escaped sequences can either be a two character hex value, or one of the\n// following single character codes\n\nfunction decodeControlCharacter(char) {\n  switch (char) {\n    case \"t\":\n      return 0x09;\n\n    case \"n\":\n      return 0x0a;\n\n    case \"r\":\n      return 0x0d;\n\n    case '\"':\n      return 0x22;\n\n    case \"\":\n      return 0x27;\n\n    case \"\\\\\":\n      return 0x5c;\n  }\n\n  return -1;\n}\n\nvar ESCAPE_CHAR = 92; // backslash\n\nvar QUOTE_CHAR = 34; // backslash\n// parse string as per the spec:\n// https://webassembly.github.io/spec/core/multipage/text/values.html#text-string\n\nfunction parseString(value) {\n  var byteArray = [];\n  var index = 0;\n\n  while (index < value.length) {\n    var charCode = value.charCodeAt(index);\n\n    if (CONTROL_CODES.indexOf(charCode) !== -1) {\n      throw new Error(\"ASCII control characters are not permitted within string literals\");\n    }\n\n    if (charCode === QUOTE_CHAR) {\n      throw new Error(\"quotes are not permitted within string literals\");\n    }\n\n    if (charCode === ESCAPE_CHAR) {\n      var firstChar = value.substr(index + 1, 1);\n      var decodedControlChar = decodeControlCharacter(firstChar);\n\n      if (decodedControlChar !== -1) {\n        // single character escaped values, e.g. \\r\n        byteArray.push(decodedControlChar);\n        index += 2;\n      } else {\n        // hex escaped values, e.g. \\2a\n        var hexValue = value.substr(index + 1, 2);\n\n        if (!/^[0-9A-F]{2}$/i.test(hexValue)) {\n          throw new Error(\"invalid character encoding\");\n        }\n\n        byteArray.push(parseInt(hexValue, 16));\n        index += 3;\n      }\n    } else {\n      // ASCII encoded values\n      byteArray.push(charCode);\n      index++;\n    }\n  }\n\n  return byteArray;\n}","\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.tokenize = tokenize;\nexports.tokens = exports.keywords = void 0;\n\nvar _helperFsm = require(\"@webassemblyjs/helper-fsm\");\n\nvar _helperCodeFrame = require(\"@webassemblyjs/helper-code-frame\");\n\n// eslint-disable-next-line\nfunction getCodeFrame(source, line, column) {\n  var loc = {\n    start: {\n      line: line,\n      column: column\n    }\n  };\n  return \"\\n\" + (0, _helperCodeFrame.codeFrameFromSource)(source, loc) + \"\\n\";\n}\n\nvar WHITESPACE = /\\s/;\nvar PARENS = /\\(|\\)/;\nvar LETTERS = /[a-z0-9_/]/i;\nvar idchar = /[a-z0-9!#$%&*+./:<=>?@\\\\[\\]^_`|~-]/i;\nvar valtypes = [\"i32\", \"i64\", \"f32\", \"f64\"];\nvar NUMBERS = /[0-9|.|_]/;\nvar NUMBER_KEYWORDS = /nan|inf/;\n\nfunction isNewLine(char) {\n  return char.charCodeAt(0) === 10 || char.charCodeAt(0) === 13;\n}\n\nfunction Token(type, value, start, end) {\n  var opts = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : {};\n  var token = {\n    type: type,\n    value: value,\n    loc: {\n      start: start,\n      end: end\n    }\n  };\n\n  if (Object.keys(opts).length > 0) {\n    // $FlowIgnore\n    token[\"opts\"] = opts;\n  }\n\n  return token;\n}\n\nvar tokenTypes = {\n  openParen: \"openParen\",\n  closeParen: \"closeParen\",\n  number: \"number\",\n  string: \"string\",\n  name: \"name\",\n  identifier: \"identifier\",\n  valtype: \"valtype\",\n  dot: \"dot\",\n  comment: \"comment\",\n  equal: \"equal\",\n  keyword: \"keyword\"\n};\nvar keywords = {\n  module: \"module\",\n  func: \"func\",\n  param: \"param\",\n  result: \"result\",\n  export: \"export\",\n  loop: \"loop\",\n  block: \"block\",\n  if: \"if\",\n  then: \"then\",\n  else: \"else\",\n  call: \"call\",\n  call_indirect: \"call_indirect\",\n  import: \"import\",\n  memory: \"memory\",\n  table: \"table\",\n  global: \"global\",\n  anyfunc: \"anyfunc\",\n  mut: \"mut\",\n  data: \"data\",\n  type: \"type\",\n  elem: \"elem\",\n  start: \"start\",\n  offset: \"offset\"\n};\nexports.keywords = keywords;\nvar NUMERIC_SEPARATOR = \"_\";\n/**\n * Build the FSM for number literals\n */\n\nvar numberLiteralFSM = new _helperFsm.FSM({\n  START: [(0, _helperFsm.makeTransition)(/-|\\+/, \"AFTER_SIGN\"), (0, _helperFsm.makeTransition)(/nan:0x/, \"NAN_HEX\", {\n    n: 6\n  }), (0, _helperFsm.makeTransition)(/nan|inf/, \"STOP\", {\n    n: 3\n  }), (0, _helperFsm.makeTransition)(/0x/, \"HEX\", {\n    n: 2\n  }), (0, _helperFsm.makeTransition)(/[0-9]/, \"DEC\"), (0, _helperFsm.makeTransition)(/\\./, \"DEC_FRAC\")],\n  AFTER_SIGN: [(0, _helperFsm.makeTransition)(/nan:0x/, \"NAN_HEX\", {\n    n: 6\n  }), (0, _helperFsm.makeTransition)(/nan|inf/, \"STOP\", {\n    n: 3\n  }), (0, _helperFsm.makeTransition)(/0x/, \"HEX\", {\n    n: 2\n  }), (0, _helperFsm.makeTransition)(/[0-9]/, \"DEC\"), (0, _helperFsm.makeTransition)(/\\./, \"DEC_FRAC\")],\n  DEC_FRAC: [(0, _helperFsm.makeTransition)(/[0-9]/, \"DEC_FRAC\", {\n    allowedSeparator: NUMERIC_SEPARATOR\n  }), (0, _helperFsm.makeTransition)(/e|E/, \"DEC_SIGNED_EXP\")],\n  DEC: [(0, _helperFsm.makeTransition)(/[0-9]/, \"DEC\", {\n    allowedSeparator: NUMERIC_SEPARATOR\n  }), (0, _helperFsm.makeTransition)(/\\./, \"DEC_FRAC\"), (0, _helperFsm.makeTransition)(/e|E/, \"DEC_SIGNED_EXP\")],\n  DEC_SIGNED_EXP: [(0, _helperFsm.makeTransition)(/\\+|-/, \"DEC_EXP\"), (0, _helperFsm.makeTransition)(/[0-9]/, \"DEC_EXP\")],\n  DEC_EXP: [(0, _helperFsm.makeTransition)(/[0-9]/, \"DEC_EXP\", {\n    allowedSeparator: NUMERIC_SEPARATOR\n  })],\n  HEX: [(0, _helperFsm.makeTransition)(/[0-9|A-F|a-f]/, \"HEX\", {\n    allowedSeparator: NUMERIC_SEPARATOR\n  }), (0, _helperFsm.makeTransition)(/\\./, \"HEX_FRAC\"), (0, _helperFsm.makeTransition)(/p|P/, \"HEX_SIGNED_EXP\")],\n  HEX_FRAC: [(0, _helperFsm.makeTransition)(/[0-9|A-F|a-f]/, \"HEX_FRAC\", {\n    allowedSeparator: NUMERIC_SEPARATOR\n  }), (0, _helperFsm.makeTransition)(/p|P|/, \"HEX_SIGNED_EXP\")],\n  HEX_SIGNED_EXP: [(0, _helperFsm.makeTransition)(/[0-9|+|-]/, \"HEX_EXP\")],\n  HEX_EXP: [(0, _helperFsm.makeTransition)(/[0-9]/, \"HEX_EXP\", {\n    allowedSeparator: NUMERIC_SEPARATOR\n  })],\n  NAN_HEX: [(0, _helperFsm.makeTransition)(/[0-9|A-F|a-f]/, \"NAN_HEX\", {\n    allowedSeparator: NUMERIC_SEPARATOR\n  })],\n  STOP: []\n}, \"START\", \"STOP\");\n\nfunction tokenize(input) {\n  var current = 0;\n  var char = input[current]; // Used by SourceLocation\n\n  var column = 1;\n  var line = 1;\n  var tokens = [];\n  /**\n   * Creates a pushToken function for a given type\n   */\n\n  function pushToken(type) {\n    return function (v) {\n      var opts = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n      var startColumn = opts.startColumn || column - String(v).length;\n      delete opts.startColumn;\n      var endColumn = opts.endColumn || startColumn + String(v).length - 1;\n      delete opts.endColumn;\n      var start = {\n        line: line,\n        column: startColumn\n      };\n      var end = {\n        line: line,\n        column: endColumn\n      };\n      tokens.push(Token(type, v, start, end, opts));\n    };\n  }\n  /**\n   * Functions to save newly encountered tokens\n   */\n\n\n  var pushCloseParenToken = pushToken(tokenTypes.closeParen);\n  var pushOpenParenToken = pushToken(tokenTypes.openParen);\n  var pushNumberToken = pushToken(tokenTypes.number);\n  var pushValtypeToken = pushToken(tokenTypes.valtype);\n  var pushNameToken = pushToken(tokenTypes.name);\n  var pushIdentifierToken = pushToken(tokenTypes.identifier);\n  var pushKeywordToken = pushToken(tokenTypes.keyword);\n  var pushDotToken = pushToken(tokenTypes.dot);\n  var pushStringToken = pushToken(tokenTypes.string);\n  var pushCommentToken = pushToken(tokenTypes.comment);\n  var pushEqualToken = pushToken(tokenTypes.equal);\n  /**\n   * Can be used to look at the next character(s).\n   *\n   * The default behavior `lookahead()` simply returns the next character without consuming it.\n   * Letters are always returned in lowercase.\n   *\n   * @param {number} length How many characters to query. Default = 1\n   * @param {number} offset How many characters to skip forward from current one. Default = 1\n   *\n   */\n\n  function lookahead() {\n    var length = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 1;\n    var offset = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;\n    return input.substring(current + offset, current + offset + length).toLowerCase();\n  }\n  /**\n   * Advances the cursor in the input by a certain amount\n   *\n   * @param {number} amount How many characters to consume. Default = 1\n   */\n\n\n  function eatCharacter() {\n    var amount = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 1;\n    column += amount;\n    current += amount;\n    char = input[current];\n  }\n\n  while (current < input.length) {\n    // ;;\n    if (char === \";\" && lookahead() === \";\") {\n      var startColumn = column;\n      eatCharacter(2);\n      var text = \"\";\n\n      while (!isNewLine(char)) {\n        text += char;\n        eatCharacter();\n\n        if (char === undefined) {\n          break;\n        }\n      }\n\n      var endColumn = column;\n      pushCommentToken(text, {\n        type: \"leading\",\n        startColumn: startColumn,\n        endColumn: endColumn\n      });\n      continue;\n    } // (;\n\n\n    if (char === \"(\" && lookahead() === \";\") {\n      var _startColumn = column;\n      eatCharacter(2);\n      var _text = \"\"; // ;)\n\n      while (true) {\n        char = input[current];\n\n        if (char === \";\" && lookahead() === \")\") {\n          eatCharacter(2);\n          break;\n        }\n\n        _text += char;\n        eatCharacter();\n\n        if (isNewLine(char)) {\n          line++;\n          column = 0;\n        }\n      }\n\n      var _endColumn = column;\n      pushCommentToken(_text, {\n        type: \"block\",\n        startColumn: _startColumn,\n        endColumn: _endColumn\n      });\n      continue;\n    }\n\n    if (char === \"(\") {\n      pushOpenParenToken(char);\n      eatCharacter();\n      continue;\n    }\n\n    if (char === \"=\") {\n      pushEqualToken(char);\n      eatCharacter();\n      continue;\n    }\n\n    if (char === \")\") {\n      pushCloseParenToken(char);\n      eatCharacter();\n      continue;\n    }\n\n    if (isNewLine(char)) {\n      line++;\n      eatCharacter();\n      column = 0;\n      continue;\n    }\n\n    if (WHITESPACE.test(char)) {\n      eatCharacter();\n      continue;\n    }\n\n    if (char === \"$\") {\n      var _startColumn2 = column;\n      eatCharacter();\n      var value = \"\";\n\n      while (idchar.test(char)) {\n        value += char;\n        eatCharacter();\n      }\n\n      var _endColumn2 = column;\n      pushIdentifierToken(value, {\n        startColumn: _startColumn2,\n        endColumn: _endColumn2\n      });\n      continue;\n    }\n\n    if (NUMBERS.test(char) || NUMBER_KEYWORDS.test(lookahead(3, 0)) || char === \"-\" || char === \"+\") {\n      var _startColumn3 = column;\n\n      var _value = numberLiteralFSM.run(input.slice(current));\n\n      if (_value === \"\") {\n        throw new Error(getCodeFrame(input, line, column) + \"Unexpected character \" + JSON.stringify(char));\n      }\n\n      pushNumberToken(_value, {\n        startColumn: _startColumn3\n      });\n      eatCharacter(_value.length);\n\n      if (char && !PARENS.test(char) && !WHITESPACE.test(char)) {\n        throw new Error(getCodeFrame(input, line, column) + \"Unexpected character \" + JSON.stringify(char));\n      }\n\n      continue;\n    }\n\n    if (char === '\"') {\n      var _startColumn4 = column;\n      var _value2 = \"\";\n      eatCharacter(); // \"\n\n      while (char !== '\"') {\n        if (isNewLine(char)) {\n          throw new Error(getCodeFrame(input, line, column) + \"Unexpected character \" + JSON.stringify(char));\n        }\n\n        _value2 += char;\n        eatCharacter(); // char\n      }\n\n      eatCharacter(); // \"\n\n      var _endColumn3 = column;\n      pushStringToken(_value2, {\n        startColumn: _startColumn4,\n        endColumn: _endColumn3\n      });\n      continue;\n    }\n\n    if (LETTERS.test(char)) {\n      var _value3 = \"\";\n      var _startColumn5 = column;\n\n      while (char && LETTERS.test(char)) {\n        _value3 += char;\n        eatCharacter();\n      }\n      /*\n       * Handle MemberAccess\n       */\n\n\n      if (char === \".\") {\n        var dotStartColumn = column;\n\n        if (valtypes.indexOf(_value3) !== -1) {\n          pushValtypeToken(_value3, {\n            startColumn: _startColumn5\n          });\n        } else {\n          pushNameToken(_value3);\n        }\n\n        eatCharacter();\n        _value3 = \"\";\n        var nameStartColumn = column;\n\n        while (LETTERS.test(char)) {\n          _value3 += char;\n          eatCharacter();\n        }\n\n        pushDotToken(\".\", {\n          startColumn: dotStartColumn\n        });\n        pushNameToken(_value3, {\n          startColumn: nameStartColumn\n        });\n        continue;\n      }\n      /*\n       * Handle keywords\n       */\n      // $FlowIgnore\n\n\n      if (typeof keywords[_value3] === \"string\") {\n        pushKeywordToken(_value3, {\n          startColumn: _startColumn5\n        });\n        continue;\n      }\n      /*\n       * Handle types\n       */\n\n\n      if (valtypes.indexOf(_value3) !== -1) {\n        pushValtypeToken(_value3, {\n          startColumn: _startColumn5\n        });\n        continue;\n      }\n      /*\n       * Handle literals\n       */\n\n\n      pushNameToken(_value3, {\n        startColumn: _startColumn5\n      });\n      continue;\n    }\n\n    throw new Error(getCodeFrame(input, line, column) + \"Unexpected character \" + JSON.stringify(char));\n  }\n\n  return tokens;\n}\n\nvar tokens = tokenTypes;\nexports.tokens = tokens;"]}